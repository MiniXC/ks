input dim=100 name=ivector
input dim=40 name=input
# please note that it is important to have input layer with the name=input
# as the layer immediately preceding the fixed-affine-layer to enable
# the use of short notation for the descriptor
fixed-affine-layer name=lda input=Append(-2,-1,0,1,2,ReplaceIndex(ivector, t, 0)) affine-transform-file=$dir/configs/lda.mat
# the first splicing is moved before the lda layer, so no splicing here
relu-renorm-layer name=tdnn1 dim=512
relu-renorm-layer name=tdnn2 dim=512 input=Append(-1,0,1)
relu-renorm-layer name=tdnn3 dim=512 input=Append(-1,0,1)
relu-renorm-layer name=tdnn4 dim=512 input=Append(-3,0,3)
relu-renorm-layer name=tdnn5 dim=512 input=Append(-3,0,3)
relu-renorm-layer name=tdnn6 dim=512 input=Append(-6,-3,0)
relu-renorm-layer name=prefinal-chain dim=512 target-rms=0.5
output-layer name=output include-log-softmax=false dim=$num_targets max-change=1.5
output-layer name=output-default input=prefinal-chain include-log-softmax=false dim=$num_targets max-change=1.5
relu-renorm-layer name=prefinal-xent input=tdnn6 dim=512 target-rms=0.5
output-layer name=output-xent dim=$num_targets learning-rate-factor=$learning_rate_factor max-change=1.5
output-layer name=output-default-xent input=prefinal-xent dim=$num_targets learning-rate-factor=$learning_rate_factor max-change=1.5